{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-28T17:34:53.000655Z",
     "start_time": "2025-05-28T17:34:50.094018Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from torch.functional import F\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from rnn_seq2seq import RNNSeq2Seq\n",
    "from lstm_seq2seq import LSTMSeq2Seq\n",
    "from gru_seq2seq import GRUSeq2Seq\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "warnings.filterwarnings('ignore')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 20:34:51.090028: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-05-28 20:34:51.097818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748453691.106132   40491 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748453691.108607   40491 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748453691.114989   40491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453691.114996   40491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453691.114997   40491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748453691.114998   40491 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 20:34:51.117303: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:34:53.261653Z",
     "start_time": "2025-05-28T17:34:53.001538Z"
    }
   },
   "cell_type": "code",
   "source": "data = pd.read_csv('Reviews.csv', nrows=100000)",
   "id": "90827b69b3ec5d99",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:34:53.301430Z",
     "start_time": "2025-05-28T17:34:53.262302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data.drop_duplicates(subset=['Text'], inplace=True)\n",
    "data.dropna(axis=0, inplace=True)"
   ],
   "id": "bc31ce9eaf2fc185",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:34:53.305670Z",
     "start_time": "2025-05-28T17:34:53.302245Z"
    }
   },
   "cell_type": "code",
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"'cause\": \"because\",\n",
    "                       \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n",
    "                       \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                       \"he'd\": \"he would\", \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\",\n",
    "                       \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\",\n",
    "                       \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\", \"I'm\": \"I am\",\n",
    "                       \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",\n",
    "                       \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                       \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\",\n",
    "                       \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n",
    "                       \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                       \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\",\n",
    "                       \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\",\n",
    "                       \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\",\n",
    "                       \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n",
    "                       \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                       \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\",\n",
    "                       \"so've\": \"so have\", \"so's\": \"so as\", \"this's\": \"this is\", \"that'd\": \"that would\",\n",
    "                       \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                       \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\n",
    "                       \"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\",\n",
    "                       \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n",
    "                       \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\",\n",
    "                       \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\",\n",
    "                       \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\",\n",
    "                       \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\",\n",
    "                       \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\",\n",
    "                       \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                       \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\",\n",
    "                       \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\",\n",
    "                       \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\n",
    "                       \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\",\n",
    "                       \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\",\n",
    "                       \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}"
   ],
   "id": "78fa1a164db531d4",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:34:53.312419Z",
     "start_time": "2025-05-28T17:34:53.306104Z"
    }
   },
   "cell_type": "code",
   "source": "data['Text'][:10]",
   "id": "20ccd10c8f6e21d4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labr...\n",
       "1             Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n",
       "2    This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with ...\n",
       "3    If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The fl...\n",
       "4                                                               Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n",
       "5    I got a wild hair for taffy and ordered this five pound bag. The taffy was all very enjoyable with many flavors: watermelon, root beer, melon, peppermint, grape, etc. My only complaint is there wa...\n",
       "6    This saltwater taffy had great flavors and was very soft and chewy.  Each candy was individually wrapped well.  None of the candies were stuck together, which did happen in the expensive version, ...\n",
       "7                                                               This taffy is so good.  It is very soft and chewy.  The flavors are amazing.  I would definitely recommend you buying it.  Very satisfying!!\n",
       "8                                                                        Right now I'm mostly just sprouting this so my cats can eat the grass. They love it. I rotate it around with Wheatgrass and Rye too\n",
       "9                                                                  This is a very healthy dog food. Good for their digestion. Also good for small puppies. My dog eats her required amount at every feeding.\n",
       "Name: Text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.456133Z",
     "start_time": "2025-05-28T17:34:53.312868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "def text_cleaner(text):\n",
    "    new_string = text.lower()\n",
    "    new_string = BeautifulSoup(new_string, 'lxml').text\n",
    "    new_string = re.sub(r'\\([^)]*\\)', '', new_string)\n",
    "    new_string = re.sub('\"', '', new_string)\n",
    "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")])\n",
    "    new_string = re.sub(r\"'s\\b\", \"\", new_string)\n",
    "    new_string = re.sub(\"[^a-zA-Z]\", \" \", new_string)\n",
    "    tokens = [w for w in new_string.split() if not w in stop_words]\n",
    "    long_words = []\n",
    "    for i in tokens:\n",
    "        if len(i) >= 3:\n",
    "            long_words.append(i)\n",
    "    return (\" \".join(long_words)).strip()\n",
    "\n",
    "\n",
    "cleaned_text = []\n",
    "for t in data['Text']:\n",
    "    cleaned_text.append(text_cleaner(t))"
   ],
   "id": "36bae2526c2f6a7b",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.459057Z",
     "start_time": "2025-05-28T17:35:01.456694Z"
    }
   },
   "cell_type": "code",
   "source": "data['Summary'][:10]",
   "id": "2e26031d0c789365",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                            Good Quality Dog Food\n",
       "1                                Not as Advertised\n",
       "2                            \"Delight\" says it all\n",
       "3                                   Cough Medicine\n",
       "4                                      Great taffy\n",
       "5                                       Nice Taffy\n",
       "6    Great!  Just as good as the expensive brands!\n",
       "7                           Wonderful, tasty taffy\n",
       "8                                       Yay Barley\n",
       "9                                 Healthy Dog Food\n",
       "Name: Summary, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.667186Z",
     "start_time": "2025-05-28T17:35:01.459518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def summary_cleaner(text):\n",
    "    new_string = re.sub('\"', '', text)\n",
    "    new_string = ' '.join([contraction_mapping[t] if t in contraction_mapping else t for t in new_string.split(\" \")])\n",
    "    new_string = re.sub(r\"'s\\b\", \"\", new_string)\n",
    "    new_string = re.sub(\"[^a-zA-Z]\", \" \", new_string)\n",
    "    new_string = new_string.lower()\n",
    "    tokens = new_string.split()\n",
    "    new_string = ''\n",
    "    for i in tokens:\n",
    "        if len(i) > 1:\n",
    "            new_string = new_string + i + ' '\n",
    "    return new_string\n",
    "\n",
    "\n",
    "cleaned_summary = []\n",
    "for t in data['Summary']:\n",
    "    cleaned_summary.append(summary_cleaner(t))"
   ],
   "id": "c932edfcad16ef7d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.701456Z",
     "start_time": "2025-05-28T17:35:01.667873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['cleaned_text'] = cleaned_text\n",
    "data['cleaned_summary'] = cleaned_summary\n",
    "data['cleaned_summary'].replace('', np.nan, inplace=True)\n",
    "data.dropna(axis=0, inplace=True)"
   ],
   "id": "a3ac67be35813ae",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.713864Z",
     "start_time": "2025-05-28T17:35:01.702607Z"
    }
   },
   "cell_type": "code",
   "source": "data['cleaned_summary'] = data['cleaned_summary'].apply(lambda x: '_START_ ' + x + ' _END_')",
   "id": "86520e2e775d5a0b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.719035Z",
     "start_time": "2025-05-28T17:35:01.714344Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in range(5):\n",
    "    print('Review: ', data['cleaned_text'][i])\n",
    "    print('Summary: ', data['cleaned_summary'][i])\n",
    "    print('\\n')"
   ],
   "id": "177d7dbae4f9a3e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review:  bought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n",
      "Summary:  _START_ good quality dog food  _END_\n",
      "\n",
      "\n",
      "Review:  product arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n",
      "Summary:  _START_ not as advertised  _END_\n",
      "\n",
      "\n",
      "Review:  confection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n",
      "Summary:  _START_ delight says it all  _END_\n",
      "\n",
      "\n",
      "Review:  looking secret ingredient robitussin believe found got addition root beer extract ordered made cherry soda flavor medicinal\n",
      "Summary:  _START_ cough medicine  _END_\n",
      "\n",
      "\n",
      "Review:  great taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n",
      "Summary:  _START_ great taffy  _END_\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.935101Z",
     "start_time": "2025-05-28T17:35:01.719512Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_word_count = []\n",
    "summary_word_count = []\n",
    "\n",
    "for i in data['cleaned_text']:\n",
    "    text_word_count.append(len(i.split()))\n",
    "\n",
    "for i in data['cleaned_summary']:\n",
    "    summary_word_count.append(len(i.split()))\n",
    "\n",
    "length_df = pd.DataFrame({'Text': text_word_count, 'Summary': summary_word_count})\n",
    "length_df.hist(bins=30)\n",
    "plt.show()"
   ],
   "id": "82a65e393e8e8aa0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.937225Z",
     "start_time": "2025-05-28T17:35:01.935597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "max_len_text = 80\n",
    "max_len_summary = 10"
   ],
   "id": "1bfcb70f17841dfb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:01.945698Z",
     "start_time": "2025-05-28T17:35:01.937685Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tr, x_val, y_tr, y_val = train_test_split(data['cleaned_text'], data['cleaned_summary'], test_size=0.1,\n",
    "                                            random_state=0, shuffle=True)"
   ],
   "id": "62fb129ee28d1a0e",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:03.723531Z",
     "start_time": "2025-05-28T17:35:01.946129Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(x_tr))\n",
    "\n",
    "x_tr = x_tokenizer.texts_to_sequences(x_tr)\n",
    "x_val = x_tokenizer.texts_to_sequences(x_val)\n",
    "\n",
    "x_tr = pad_sequences(x_tr, maxlen=max_len_text, padding='post')\n",
    "x_val = pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size = len(x_tokenizer.word_index) + 1"
   ],
   "id": "50719e1ebb67e767",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.363945Z",
     "start_time": "2025-05-28T17:35:03.724060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_tr))\n",
    "\n",
    "y_tr = y_tokenizer.texts_to_sequences(y_tr)\n",
    "y_val = y_tokenizer.texts_to_sequences(y_val)\n",
    "\n",
    "y_tr = pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
    "y_val = pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size = len(y_tokenizer.word_index) + 1"
   ],
   "id": "c205701f503095df",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.389696Z",
     "start_time": "2025-05-28T17:35:04.364649Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x_tr).long(), torch.from_numpy(y_tr).long())\n",
    "val_data = TensorDataset(torch.from_numpy(x_val).long(), torch.from_numpy(y_val).long())\n",
    "train_loader = DataLoader(train_data, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=512, shuffle=True)"
   ],
   "id": "7e10fe83dac2936c",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.393573Z",
     "start_time": "2025-05-28T17:35:04.391243Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def accuracy(outputs, targets):\n",
    "    flattened_outputs = outputs[:, 1:, :].argmax(dim=-1).flatten()\n",
    "    flattened_targets = targets[:, 1:].flatten()\n",
    "    accuracies = flattened_outputs.eq(flattened_targets)\n",
    "    mask = torch.logical_not(flattened_outputs.eq(0))\n",
    "    accuracies = torch.logical_and(mask, accuracies)\n",
    "    return (accuracies.sum() / mask.sum()).item()"
   ],
   "id": "e370e4572a7d244d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.398758Z",
     "start_time": "2025-05-28T17:35:04.394154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_and_validate(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_):\n",
    "    train_losses, val_losses, val_accs = [], [], []\n",
    "\n",
    "    for epoch in range(epochs_):\n",
    "        model_.train()\n",
    "        total_train_loss = 0\n",
    "        for (inputs, targets) in train_loader_:\n",
    "            inputs, targets = inputs.to(device_), targets.to(device_)\n",
    "            outputs = model_(inputs, targets)\n",
    "            loss = criterion_(outputs[:, 1:, :].flatten(start_dim=0, end_dim=1), targets[:, 1:].flatten())\n",
    "            total_train_loss += loss.item()\n",
    "            optimizer_.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_.step()\n",
    "\n",
    "        model_.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for (inputs, targets) in val_loader_:\n",
    "                inputs, targets = inputs.to(device_), targets.to(device_)\n",
    "                outputs = model_(inputs, targets, 0)\n",
    "                loss = criterion_(outputs[:, 1:, :].flatten(start_dim=0, end_dim=1), targets[:, 1:].flatten())\n",
    "                total_val_loss += loss.item()\n",
    "                total_val_acc += accuracy(outputs, targets)\n",
    "\n",
    "        total_train_loss = total_train_loss / len(train_loader_)\n",
    "        total_val_loss = total_val_loss / len(val_loader_)\n",
    "        total_val_acc = total_val_acc / len(val_loader_)\n",
    "\n",
    "        train_losses.append(total_train_loss)\n",
    "        val_losses.append(total_val_loss)\n",
    "        val_accs.append(total_val_acc)\n",
    "        print(\n",
    "            f'Epoch: {epoch + 1} / {epochs_} | Train loss: {total_train_loss} | Val loss: {total_val_loss} | Val acc: {total_val_acc}')\n",
    "    return train_losses, val_losses, val_accs\n"
   ],
   "id": "1c1e654b4bac2c36",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.402758Z",
     "start_time": "2025-05-28T17:35:04.399493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_losses(model_name, train_losses, val_losses, epochs):\n",
    "    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
    "    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n",
    "    plt.title(f'Training and Validation Losses for {model_name}')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "4ed82bfb9a3ea318",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.405990Z",
     "start_time": "2025-05-28T17:35:04.403309Z"
    }
   },
   "cell_type": "code",
   "source": [
    "target_word_index = y_tokenizer.word_index\n",
    "reverse_target_word_index = y_tokenizer.index_word\n",
    "reverse_source_word_index = x_tokenizer.index_word"
   ],
   "id": "630cfed146b74f02",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.410674Z",
     "start_time": "2025-05-28T17:35:04.406555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def decode_sequence(input_seq, model_, rnn_type='rnn'):\n",
    "    if rnn_type == 'lstm':\n",
    "        _, hidden, cell_state = model_.encoder(torch.IntTensor(input_seq).to(device))\n",
    "    else:\n",
    "        _, hidden = model_.encoder(torch.IntTensor(input_seq).to(device))\n",
    "\n",
    "    target_seq = torch.zeros(1, dtype=torch.int64).to(device)\n",
    "    target_seq[0] = target_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        embedded_seq = model_.decoder_embedder(target_seq.unsqueeze(1))\n",
    "        if rnn_type == 'lstm':\n",
    "            prediction, hidden, _ = model_.decoder(embedded_seq, hidden, cell_state)\n",
    "        else:\n",
    "            prediction, hidden = model_.decoder(embedded_seq, hidden)\n",
    "        prediction_index = prediction.argmax(dim=-1)[0].item()\n",
    "        predicted_word = reverse_target_word_index[prediction_index]\n",
    "\n",
    "        if predicted_word != 'end':\n",
    "            decoded_sentence += ' ' + predicted_word\n",
    "\n",
    "        if predicted_word == 'end' or len(decoded_sentence.split()) >= max_len_summary - 1:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = torch.zeros(1, dtype=torch.int64).to(device)\n",
    "        target_seq[0] = prediction_index\n",
    "\n",
    "    return decoded_sentence\n"
   ],
   "id": "154d057e13fee1b3",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:35:04.414602Z",
     "start_time": "2025-05-28T17:35:04.411251Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def seq2summary(input_seq):\n",
    "    new_string = ''\n",
    "    for i in input_seq:\n",
    "        if (i != 0 and i != target_word_index['start']) and i != target_word_index['end']:\n",
    "            new_string = new_string + reverse_target_word_index[i] + ' '\n",
    "    return new_string\n",
    "\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    new_string = ''\n",
    "    for i in input_seq:\n",
    "        if i != 0:\n",
    "            new_string = new_string + reverse_source_word_index[i] + ' '\n",
    "    return new_string\n"
   ],
   "id": "520b50aa6548bd01",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RNN Seq2Seq",
   "id": "b46f922961209f7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:52:03.123636Z",
     "start_time": "2025-05-28T17:52:02.994379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "c90528499fdafb0a",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T17:54:51.122928Z",
     "start_time": "2025-05-28T17:52:03.969053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('RNNSeq2Seq Start Training:')\n",
    "rnn_train_losses, rnn_val_losses, rnn_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "bb95edf138fbf350",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNSeq2Seq Start Training:\n",
      "Epoch: 1 / 20 | Train loss: 5.630729686981623 | Val loss: 5.7365113543925315 | Val acc: 0.12014169170189712\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRNNSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m rnn_train_losses, rnn_val_losses, rnn_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 13\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     12\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('RNN', rnn_train_losses, rnn_val_losses, epochs)",
   "id": "6f8c48e4d12473ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model))\n",
    "    break"
   ],
   "id": "6fb4a456c0f07d76",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RNN Seq2Seq With Attention",
   "id": "a2ca518372dca0e6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:14:00.839879Z",
     "start_time": "2025-05-28T18:14:00.716819Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "6f6a2e6abac4fb3a",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:16:14.874263Z",
     "start_time": "2025-05-28T18:14:01.494569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('RNNSeq2Seq Start Training:')\n",
    "rnn_train_losses, rnn_val_losses, rnn_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "f1c75d0ed04e5c95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNSeq2Seq Start Training:\n",
      "Epoch: 1 / 20 | Train loss: 5.827089460146345 | Val loss: 5.8689067808248225 | Val acc: 0.11116133171454662\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[42], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRNNSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m rnn_train_losses, rnn_val_losses, rnn_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 13\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     12\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('RNN', rnn_train_losses, rnn_val_losses, epochs)",
   "id": "4349f82da3485a90",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model))\n",
    "    break"
   ],
   "id": "5c1ef96ca297dec1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# RNN Seq2Seq With Attention and BiDirectional Encoder",
   "id": "8ac9f100c4e533ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:16:21.081521Z",
     "start_time": "2025-05-28T18:16:20.961311Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = RNNSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True, encoder_modes='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "ad785dafa52718c5",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:19:39.386286Z",
     "start_time": "2025-05-28T18:16:21.859652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('RNNSeq2Seq Start Training:')\n",
    "rnn_train_losses, rnn_val_losses, rnn_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "520b33f19f0d0f96",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNNSeq2Seq Start Training:\n",
      "Epoch: 1 / 20 | Train loss: 5.955836038032019 | Val loss: 6.008210656333104 | Val acc: 0.11118644160234321\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[44], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRNNSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m rnn_train_losses, rnn_val_losses, rnn_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 13\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     12\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('RNN', rnn_train_losses, rnn_val_losses, epochs)",
   "id": "4c97b82f8d32d589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model))\n",
    "    break"
   ],
   "id": "9ca9cf23d79e35c0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM Seq2Seq",
   "id": "e52fc3960afce4f1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:19:43.647784Z",
     "start_time": "2025-05-28T18:19:43.491164Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "1bbf45426daa174d",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:23:18.286347Z",
     "start_time": "2025-05-28T18:19:43.845244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('LSTMSeq2Seq Start Training:')\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "34d997bf7f3f98c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMSeq2Seq Start Training:\n",
      "Epoch: 1 / 20 | Train loss: 5.741960872875528 | Val loss: 5.503278527556166 | Val acc: 0.12204824728985965\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[46], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLSTMSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lstm_train_losses, lstm_val_losses, lstm_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 13\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     12\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('LSTM', lstm_train_losses, lstm_val_losses, epochs)",
   "id": "d782a80be6bb2c58",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model, rnn_type='lstm'))\n",
    "    break"
   ],
   "id": "edd129fbf85095e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM Seq2Seq With Attention",
   "id": "ba3b261faf3fd5a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:23:27.303200Z",
     "start_time": "2025-05-28T18:23:27.170173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "7deb4f792e5988cd",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:26:37.273805Z",
     "start_time": "2025-05-28T18:23:27.699256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('LSTMSeq2Seq Start Training:')\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "c991634e8046e3e3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMSeq2Seq Start Training:\n",
      "Epoch: 1 / 10 | Train loss: 5.40076429150076 | Val loss: 5.389430970121912 | Val acc: 0.11781903023773667\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[48], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLSTMSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lstm_train_losses, lstm_val_losses, lstm_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 9\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (inputs, targets) \u001B[38;5;129;01min\u001B[39;00m train_loader_:\n\u001B[1;32m      8\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device_), targets\u001B[38;5;241m.\u001B[39mto(device_)\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion_(outputs[:, \u001B[38;5;241m1\u001B[39m:, :]\u001B[38;5;241m.\u001B[39mflatten(start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), targets[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:133\u001B[0m, in \u001B[0;36mLSTMSeq2Seq.forward\u001B[0;34m(self, enc_input, target, teacher_forcing_ratio)\u001B[0m\n\u001B[1;32m    130\u001B[0m b, seq_len \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    131\u001B[0m outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(b, seq_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec_vocab_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m--> 133\u001B[0m enc_output, hidden, cell_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m dec_input \u001B[38;5;241m=\u001B[39m target[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(seq_len):\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:95\u001B[0m, in \u001B[0;36mLSTMEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     94\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedder(x)\n\u001B[0;32m---> 95\u001B[0m     out, hidden, cell_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out, hidden, cell_state\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:83\u001B[0m, in \u001B[0;36mLSTMBlock.forward\u001B[0;34m(self, x, hidden_state, cell_state)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cell_state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     81\u001B[0m         cell_state \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39minit_zero_cell(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m---> 83\u001B[0m     x, hidden_state, cell_state \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, hidden_state, cell_state\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:27\u001B[0m, in \u001B[0;36mLSTMLayer.forward\u001B[0;34m(self, x, hidden_state, cell_state)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(seq_len):\n\u001B[1;32m     26\u001B[0m     x_t \u001B[38;5;241m=\u001B[39m x[:, t, :]\n\u001B[0;32m---> 27\u001B[0m     f_t, i_t, g_t, o_t \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mU_f\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_f(hidden_state_f))\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;241m4\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m     28\u001B[0m     cell_state_f \u001B[38;5;241m=\u001B[39m cell_state_f \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(f_t) \u001B[38;5;241m+\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(i_t) \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39mtanh(g_t)\n\u001B[1;32m     29\u001B[0m     hidden_state_f \u001B[38;5;241m=\u001B[39m o_t \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39mtanh(cell_state_f)\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('LSTM', lstm_train_losses, lstm_val_losses, epochs)",
   "id": "5b2a0c2520b297de",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model, 'lstm'))\n",
    "    break"
   ],
   "id": "bf823ed3991b67f8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# LSTM Seq2Seq With Attention and BiDirectional Encoder",
   "id": "8f319a616bae8c1e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:26:45.551245Z",
     "start_time": "2025-05-28T18:26:45.417221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LSTMSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True, encoder_modes='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "b0ff0cb198062e3e",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:24.886359Z",
     "start_time": "2025-05-28T18:26:45.734359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('LSTMSeq2Seq Start Training:')\n",
    "lstm_train_losses, lstm_val_losses, lstm_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "d3eb0326a0151a8e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMSeq2Seq Start Training:\n",
      "Epoch: 1 / 10 | Train loss: 5.431866398253282 | Val loss: 5.394755164108707 | Val acc: 0.12006815586049678\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLSTMSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m lstm_train_losses, lstm_val_losses, lstm_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 9\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (inputs, targets) \u001B[38;5;129;01min\u001B[39;00m train_loader_:\n\u001B[1;32m      8\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device_), targets\u001B[38;5;241m.\u001B[39mto(device_)\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion_(outputs[:, \u001B[38;5;241m1\u001B[39m:, :]\u001B[38;5;241m.\u001B[39mflatten(start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), targets[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:133\u001B[0m, in \u001B[0;36mLSTMSeq2Seq.forward\u001B[0;34m(self, enc_input, target, teacher_forcing_ratio)\u001B[0m\n\u001B[1;32m    130\u001B[0m b, seq_len \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    131\u001B[0m outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(b, seq_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec_vocab_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m--> 133\u001B[0m enc_output, hidden, cell_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    135\u001B[0m dec_input \u001B[38;5;241m=\u001B[39m target[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(seq_len):\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:95\u001B[0m, in \u001B[0;36mLSTMEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     94\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedder(x)\n\u001B[0;32m---> 95\u001B[0m     out, hidden, cell_state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out, hidden, cell_state\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:83\u001B[0m, in \u001B[0;36mLSTMBlock.forward\u001B[0;34m(self, x, hidden_state, cell_state)\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m cell_state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     81\u001B[0m         cell_state \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39minit_zero_cell(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m---> 83\u001B[0m     x, hidden_state, cell_state \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_state\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcell_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, hidden_state, cell_state\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/lstm_seq2seq.py:41\u001B[0m, in \u001B[0;36mLSTMLayer.forward\u001B[0;34m(self, x, hidden_state, cell_state)\u001B[0m\n\u001B[1;32m     39\u001B[0m x_t \u001B[38;5;241m=\u001B[39m x[:, t, :]\n\u001B[1;32m     40\u001B[0m f_t, i_t, g_t, o_t \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mU_b(x_t) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_b(hidden_state_b))\u001B[38;5;241m.\u001B[39mchunk(\u001B[38;5;241m4\u001B[39m, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 41\u001B[0m cell_state_b \u001B[38;5;241m=\u001B[39m cell_state_b \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(f_t) \u001B[38;5;241m+\u001B[39m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43mi_t\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39mtanh(g_t)\n\u001B[1;32m     42\u001B[0m hidden_state_b \u001B[38;5;241m=\u001B[39m o_t \u001B[38;5;241m*\u001B[39m F\u001B[38;5;241m.\u001B[39mtanh(cell_state_b)\n\u001B[1;32m     43\u001B[0m out_backward[:, t, :] \u001B[38;5;241m=\u001B[39m hidden_state_b\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/functional.py:2284\u001B[0m, in \u001B[0;36msigmoid\u001B[0;34m(input)\u001B[0m\n\u001B[1;32m   2277\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21msigmoid\u001B[39m(\u001B[38;5;28minput\u001B[39m):  \u001B[38;5;66;03m# noqa: D400,D402\u001B[39;00m\n\u001B[1;32m   2278\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"sigmoid(input) -> Tensor\u001B[39;00m\n\u001B[1;32m   2279\u001B[0m \n\u001B[1;32m   2280\u001B[0m \u001B[38;5;124;03m    Applies the element-wise function :math:`\\text{Sigmoid}(x) = \\frac{1}{1 + \\exp(-x)}`\u001B[39;00m\n\u001B[1;32m   2281\u001B[0m \n\u001B[1;32m   2282\u001B[0m \u001B[38;5;124;03m    See :class:`~torch.nn.Sigmoid` for more details.\u001B[39;00m\n\u001B[1;32m   2283\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 2284\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msigmoid\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('LSTM', lstm_train_losses, lstm_val_losses, epochs)",
   "id": "be168eccbf191ce7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model, 'lstm'))\n",
    "    break"
   ],
   "id": "9811079ba4909884",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GRU Seq2Seq",
   "id": "9848f9738530eb67"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:32:29.196654Z",
     "start_time": "2025-05-28T18:32:29.088872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "5ea8b53145a4fbc",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:35:21.699490Z",
     "start_time": "2025-05-28T18:32:29.602456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('GRUSeq2Seq Start Training:')\n",
    "gru_train_losses, gru_val_losses, gru_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "5dece6ffa85d21ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUSeq2Seq Start Training:\n",
      "Epoch: 1 / 10 | Train loss: 5.447961830927994 | Val loss: 5.443006507420944 | Val acc: 0.12315846133535191\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[52], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGRUSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m gru_train_losses, gru_val_losses, gru_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 9\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (inputs, targets) \u001B[38;5;129;01min\u001B[39;00m train_loader_:\n\u001B[1;32m      8\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device_), targets\u001B[38;5;241m.\u001B[39mto(device_)\n\u001B[0;32m----> 9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion_(outputs[:, \u001B[38;5;241m1\u001B[39m:, :]\u001B[38;5;241m.\u001B[39mflatten(start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), targets[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mflatten())\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/gru_seq2seq.py:130\u001B[0m, in \u001B[0;36mGRUSeq2Seq.forward\u001B[0;34m(self, enc_input, target, teacher_forcing_ratio)\u001B[0m\n\u001B[1;32m    127\u001B[0m b, seq_len \u001B[38;5;241m=\u001B[39m target\u001B[38;5;241m.\u001B[39msize()\n\u001B[1;32m    128\u001B[0m outputs \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(b, seq_len, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdec_vocab_size)\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m--> 130\u001B[0m enc_output, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\u001B[43menc_input\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    132\u001B[0m dec_input \u001B[38;5;241m=\u001B[39m target[:, \u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(seq_len):\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/gru_seq2seq.py:92\u001B[0m, in \u001B[0;36mGRUEncoder.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m     91\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedder(x)\n\u001B[0;32m---> 92\u001B[0m     out, hidden \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgru\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m out, hidden\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/gru_seq2seq.py:80\u001B[0m, in \u001B[0;36mGRUBlock.forward\u001B[0;34m(self, x, hidden_state)\u001B[0m\n\u001B[1;32m     78\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m hidden_state \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     79\u001B[0m         hidden_state \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39minit_zero_hidden(x\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m---> 80\u001B[0m     x, hidden_state \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_state\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x, hidden_state\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1751\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1749\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1750\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1751\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1762\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1757\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1758\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1760\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1761\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1762\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1764\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1765\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/text_summarization/abstractive/gru_seq2seq.py:25\u001B[0m, in \u001B[0;36mGRULayer.forward\u001B[0;34m(self, x, hidden_state)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(seq_len):\n\u001B[1;32m     24\u001B[0m     x_t \u001B[38;5;241m=\u001B[39m x[:, t, :]\n\u001B[0;32m---> 25\u001B[0m     combined \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_t\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_state_f\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     z_t \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_z(combined))\n\u001B[1;32m     27\u001B[0m     r_t \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39msigmoid(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mW_r(combined))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('GRU', gru_train_losses, gru_val_losses, epochs)",
   "id": "14a9cfffcb4b9737",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model, rnn_type='gru'))\n",
    "    break"
   ],
   "id": "33d9663cde597afd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GRU Seq2Seq With Attention",
   "id": "72b745e22f73ce2e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:35:26.404290Z",
     "start_time": "2025-05-28T18:35:26.189052Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "92d035b81780ad77",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:38:32.988499Z",
     "start_time": "2025-05-28T18:35:27.340520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('GRUSeq2Seq Start Training:')\n",
    "gru_train_losses, gru_val_losses, gru_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "9adc8ca5a4db4a8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUSeq2Seq Start Training:\n",
      "Epoch: 1 / 10 | Train loss: 5.542223294076494 | Val loss: 5.473783282910363 | Val acc: 0.10657519535661417\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGRUSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m gru_train_losses, gru_val_losses, gru_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 8\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m      6\u001B[0m total_train_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m (inputs, targets) \u001B[38;5;129;01min\u001B[39;00m train_loader_:\n\u001B[0;32m----> 8\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m \u001B[43minputs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice_\u001B[49m\u001B[43m)\u001B[49m, targets\u001B[38;5;241m.\u001B[39mto(device_)\n\u001B[1;32m      9\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m model_(inputs, targets)\n\u001B[1;32m     10\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion_(outputs[:, \u001B[38;5;241m1\u001B[39m:, :]\u001B[38;5;241m.\u001B[39mflatten(start_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, end_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m), targets[:, \u001B[38;5;241m1\u001B[39m:]\u001B[38;5;241m.\u001B[39mflatten())\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('GRU', gru_train_losses, gru_val_losses, epochs)",
   "id": "85721dc2e31a643e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model, 'gru'))\n",
    "    break"
   ],
   "id": "47b7dd35bc18b531",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GRU Seq2Seq With Attention and BiDirectional Encoder",
   "id": "3ae753c2dd5543db"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:38:37.435613Z",
     "start_time": "2025-05-28T18:38:37.310333Z"
    }
   },
   "cell_type": "code",
   "source": [
    "epochs = 10\n",
    "embedding_dim = 400\n",
    "hidden_dim = 512\n",
    "enc_layers = 3\n",
    "dec_layers = 1\n",
    "enc_vocab_size = x_voc_size\n",
    "dec_vocab_size = y_voc_size\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GRUSeq2Seq(embedding_dim, hidden_dim, enc_layers, dec_layers, enc_vocab_size, dec_vocab_size, attention=True, encoder_modes='sum').to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)"
   ],
   "id": "4989afbae177e93d",
   "outputs": [],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-28T18:44:02.256405Z",
     "start_time": "2025-05-28T18:38:37.925917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('GRUSeq2Seq Start Training:')\n",
    "gru_train_losses, gru_val_losses, gru_val_accs = train_and_validate(model, optimizer, criterion, train_loader,\n",
    "                                                                    val_loader, epochs, device)"
   ],
   "id": "e12071cf9df31bce",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRUSeq2Seq Start Training:\n",
      "Epoch: 1 / 10 | Train loss: 5.364376932476243 | Val loss: 5.374132253355899 | Val acc: 0.08905210274424256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[56], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGRUSeq2Seq Start Training:\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 2\u001B[0m gru_train_losses, gru_val_losses, gru_val_accs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_and_validate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                                                                    \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[19], line 13\u001B[0m, in \u001B[0;36mtrain_and_validate\u001B[0;34m(model_, optimizer_, criterion_, train_loader_, val_loader_, epochs_, device_)\u001B[0m\n\u001B[1;32m     11\u001B[0m     total_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n\u001B[1;32m     12\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 13\u001B[0m     \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     14\u001B[0m     optimizer_\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     16\u001B[0m model_\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/_tensor.py:648\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    639\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    640\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    641\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    646\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    647\u001B[0m     )\n\u001B[0;32m--> 648\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    649\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    650\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:353\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    348\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    350\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[1;32m    351\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    352\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 353\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    355\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    356\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    357\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    358\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    359\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    360\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    361\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/my_projects/NaturalLanguageProcessingTasks/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:824\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[0;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[1;32m    822\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[1;32m    823\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 824\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[1;32m    827\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m    828\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_losses('GRU', gru_train_losses, gru_val_losses, epochs)",
   "id": "3652c23993a03232",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for i in range(len(x_val)):\n",
    "    print('Review: ', seq2text(x_val[i]))\n",
    "    print('Original summary: ', seq2summary(y_val[i]))\n",
    "    print('Predicted summary: ', decode_sequence(x_val[i].reshape(1, max_len_text), model))\n",
    "    break"
   ],
   "id": "cc6596772041c66f",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
