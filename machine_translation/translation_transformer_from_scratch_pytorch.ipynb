{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPIvoBMMmuwyn/0MFLgs8k5",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tonystark11/transformer-from-scratch/blob/main/src/translation_transformer_from_scratch_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installations"
   ],
   "metadata": {
    "id": "3Ey--O2jcRnW"
   }
  },
  {
   "cell_type": "code",
   "source": "# !pip install -U 'spacy[cuda-autodetect]' -q",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PgR32j24cTR9",
    "outputId": "def46b80-a383-418c-f537-49f811101d1d",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.412771Z",
     "start_time": "2025-05-30T18:15:03.410939Z"
    }
   },
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "source": [
    "# !python -m spacy download en_core_web_sm\n",
    "# !python -m spacy download es_core_news_sm"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PWJoajxGHupW",
    "outputId": "cbcbcc2f-f0ad-41d5-9c1f-419839265eee",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.671225Z",
     "start_time": "2025-05-30T18:15:03.668874Z"
    }
   },
   "outputs": [],
   "execution_count": 45
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "id": "96u-2MGiXs-4"
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "giaE9jhGXmY-",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.681819Z",
     "start_time": "2025-05-30T18:15:03.679957Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "ydNngtERXu4H",
    "outputId": "ca1d569d-1cf6-4ce2-e665-99a966cb8d7b",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.697774Z",
     "start_time": "2025-05-30T18:15:03.695680Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "source": [
    "random_seed = 42"
   ],
   "metadata": {
    "id": "SieEu-aCLUUn",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.747770Z",
     "start_time": "2025-05-30T18:15:03.745867Z"
    }
   },
   "outputs": [],
   "execution_count": 48
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MultiHeadAttention"
   ],
   "metadata": {
    "id": "mJawqQ9GX8rF"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "\n",
    "        self.W_q = nn.Linear(d_model, d_model)\n",
    "        self.W_k = nn.Linear(d_model, d_model)\n",
    "        self.W_v = nn.Linear(d_model, d_model)\n",
    "        self.W_o = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "\n",
    "    def split_heads(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        return x.reshape(batch_size, seq_len, self.num_heads, self.d_k).transpose(1, 2)\n",
    "\n",
    "    def combine_heads(self, x):\n",
    "        batch_size, _, seq_len, d_k = x.size()\n",
    "        return x.transpose(1, 2).reshape(batch_size, seq_len, self.d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output\n"
   ],
   "metadata": {
    "id": "CnGEAqsBXzkU",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.758271Z",
     "start_time": "2025-05-30T18:15:03.754890Z"
    }
   },
   "outputs": [],
   "execution_count": 49
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Position wise Feed Forward Network"
   ],
   "metadata": {
    "id": "L7yfVhkMYEhx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ],
   "metadata": {
    "id": "nhLEdRqBYAyN",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.782382Z",
     "start_time": "2025-05-30T18:15:03.779236Z"
    }
   },
   "outputs": [],
   "execution_count": 50
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Positional Encoding"
   ],
   "metadata": {
    "id": "nv9loWVOYKQt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_seq_length, d_model, device=device)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float, device=device).unsqueeze(1)\n",
    "        div_term = torch.pow(10_000, (-torch.arange(0, d_model, 2, device=device).float() / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ],
   "metadata": {
    "id": "_SqsjrSaYIlt",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.835902Z",
     "start_time": "2025-05-30T18:15:03.833405Z"
    }
   },
   "outputs": [],
   "execution_count": 51
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder Layer"
   ],
   "metadata": {
    "id": "ZKUrDvlYYRWk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x\n"
   ],
   "metadata": {
    "id": "i-Suvxv0YOqh",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.856743Z",
     "start_time": "2025-05-30T18:15:03.853635Z"
    }
   },
   "outputs": [],
   "execution_count": 52
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decoder Layer"
   ],
   "metadata": {
    "id": "Z8ySRXYzYYH9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ],
   "metadata": {
    "id": "HRTalpKJYU6P",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.903995Z",
     "start_time": "2025-05-30T18:15:03.899694Z"
    }
   },
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transformer Model"
   ],
   "metadata": {
    "id": "YubbLshNYekk"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length, device=device), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ],
   "metadata": {
    "id": "x6RA6zpgYbHF",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.922024Z",
     "start_time": "2025-05-30T18:15:03.916971Z"
    }
   },
   "outputs": [],
   "execution_count": 54
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load Data"
   ],
   "metadata": {
    "id": "5Fu_f8PgYnXw"
   }
  },
  {
   "cell_type": "code",
   "source": "# !wget https://www.manythings.org/anki/spa-eng.zip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hi6nauuSYhQR",
    "outputId": "1002321f-5af3-43fc-af7f-f4d350b923f7",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.939720Z",
     "start_time": "2025-05-30T18:15:03.938167Z"
    }
   },
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": "# !unzip spa-eng.zip",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h14iqrxHZOXI",
    "outputId": "c7cb0ca8-04cd-49f1-a90f-777679df96f8",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:03.989261Z",
     "start_time": "2025-05-30T18:15:03.987450Z"
    }
   },
   "outputs": [],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "with open('spa.txt', 'r') as f:\n",
    "    lines = f.readlines()"
   ],
   "metadata": {
    "id": "uptfO7IsZ2TO",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.024895Z",
     "start_time": "2025-05-30T18:15:04.002952Z"
    }
   },
   "outputs": [],
   "execution_count": 57
  },
  {
   "cell_type": "code",
   "source": [
    "len(lines)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HECjSS1lZ-x3",
    "outputId": "8c9fb2ee-0799-4ec8-b595-cdc3a3b797a2",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.030163Z",
     "start_time": "2025-05-30T18:15:04.028173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141543"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 58
  },
  {
   "cell_type": "code",
   "source": [
    "lines[10000]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "bsswMXSfaAy6",
    "outputId": "416cfe6c-01c4-4e06-8421-ff933f5603fe",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.075437Z",
     "start_time": "2025-05-30T18:15:04.073263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't see you.\\tNo puedo veros.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #1784974 (Amastan) & #1784978 (Shishir)\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove everything after the 2nd tab character.\n",
    "# As we can see above, we only need the first two columns of the data\n",
    "lines = [line.split('\\t') for line in lines]\n",
    "lines = ['\\t'.join(line[:2]) for line in lines]"
   ],
   "metadata": {
    "id": "OUCSX2QzaEJM",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.317237Z",
     "start_time": "2025-05-30T18:15:04.091099Z"
    }
   },
   "outputs": [],
   "execution_count": 60
  },
  {
   "cell_type": "code",
   "source": [
    "lines[10000]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mYLNfLd9aMYw",
    "outputId": "d5737dd7-089c-4f4b-8185-f79b948cd945",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.320397Z",
     "start_time": "2025-05-30T18:15:04.317983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I can't see you.\\tNo puedo veros.\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 61
  },
  {
   "cell_type": "code",
   "source": [
    "# Create train, val, test split\n",
    "train_lines, val_test_lines = train_test_split(lines, test_size=0.2, random_state=random_seed, shuffle=True)\n",
    "val_lines, test_lines = train_test_split(val_test_lines, test_size=0.5, random_state=random_seed, shuffle=True)"
   ],
   "metadata": {
    "id": "0jrrLdoMKRs-",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.349447Z",
     "start_time": "2025-05-30T18:15:04.320887Z"
    }
   },
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(train_lines))\n",
    "print(len(val_lines))\n",
    "print(len(test_lines))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXX2WcrTLlPO",
    "outputId": "0a35df38-3cb0-48fd-8563-f58b7fe42b1e",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.352025Z",
     "start_time": "2025-05-30T18:15:04.350284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113234\n",
      "14154\n",
      "14155\n"
     ]
    }
   ],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "source": [
    "train_lines[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NJwO1OCELxwM",
    "outputId": "d1ec50ee-e52a-4970-a7bb-66e1ec24bf9f",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.356757Z",
     "start_time": "2025-05-30T18:15:04.352531Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why didn't you use a pay phone?\\t¿Por qué no usaste un teléfono de pago?\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "source": [
    "val_lines[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wuOmjimML1GB",
    "outputId": "9078578e-726d-4915-b87a-8a465ab2a582",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.361587Z",
     "start_time": "2025-05-30T18:15:04.357404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tom advised Mary to go to see a doctor.\\tTom le aconsejó a Mary que vaya a ver al doctor.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "source": [
    "test_lines[0]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "5CIt4obBL3fK",
    "outputId": "b482b4d6-57f4-48ae-be0c-524548b50880",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.365143Z",
     "start_time": "2025-05-30T18:15:04.362111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Tom's flight was delayed.\\tEl vuelo de Tom fue retrasado.\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 66
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocess Data"
   ],
   "metadata": {
    "id": "EA5cl9qOIukd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "SRC_LANGUAGE = \"en\"\n",
    "TGT_LANGUAGE = \"es\""
   ],
   "metadata": {
    "id": "XWO6oUP9aQrE",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.368683Z",
     "start_time": "2025-05-30T18:15:04.365705Z"
    }
   },
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = {}\n",
    "tokenizer[SRC_LANGUAGE] = get_tokenizer(\"spacy\", \"en_core_web_sm\")\n",
    "tokenizer[TGT_LANGUAGE] = get_tokenizer(\"spacy\", \"es_core_news_sm\")"
   ],
   "metadata": {
    "id": "K57FvxR9HjHS",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.718027Z",
     "start_time": "2025-05-30T18:15:04.369110Z"
    }
   },
   "outputs": [],
   "execution_count": 68
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Dataset"
   ],
   "metadata": {
    "id": "av5y5eatMm3P"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "class SentencePairDataset(Dataset):\n",
    "    def __init__(self, lines, src_tokenizer, tgt_tokenizer):\n",
    "        super(SentencePairDataset, self).__init__()\n",
    "\n",
    "        self.lines = lines\n",
    "        self.src_tokenizer = src_tokenizer\n",
    "        self.tgt_tokenizer = tgt_tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        line = self.lines[idx]\n",
    "\n",
    "        src, tgt = line.split('\\t')\n",
    "        src_tokens = self.src_tokenizer(src)\n",
    "        tgt_tokens = self.tgt_tokenizer(tgt)\n",
    "\n",
    "        return src_tokens, tgt_tokens"
   ],
   "metadata": {
    "id": "9pQb9TXQIQHU",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.721946Z",
     "start_time": "2025-05-30T18:15:04.719496Z"
    }
   },
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds = SentencePairDataset(train_lines, tokenizer[SRC_LANGUAGE], tokenizer[TGT_LANGUAGE])\n",
    "val_ds = SentencePairDataset(val_lines, tokenizer[SRC_LANGUAGE], tokenizer[TGT_LANGUAGE])\n",
    "test_ds = SentencePairDataset(test_lines, tokenizer[SRC_LANGUAGE], tokenizer[TGT_LANGUAGE])"
   ],
   "metadata": {
    "id": "_VhZbqdSKIn5",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:04.726331Z",
     "start_time": "2025-05-30T18:15:04.722564Z"
    }
   },
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "source": [
    "# Length of longest src sequence\n",
    "print(max(len(x[0]) for x in train_ds))\n",
    "print(max(len(x[0]) for x in val_ds))\n",
    "print(max(len(x[0]) for x in test_ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hpBOyY4vqwfi",
    "outputId": "019210aa-3cfb-4ad4-f8fa-fe3709d73263",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:08.377404Z",
     "start_time": "2025-05-30T18:15:04.726942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n",
      "46\n",
      "32\n"
     ]
    }
   ],
   "execution_count": 71
  },
  {
   "cell_type": "code",
   "source": [
    "# Length of longest tgt sequence\n",
    "print(max(len(x[1]) for x in train_ds))\n",
    "print(max(len(x[1]) for x in val_ds))\n",
    "print(max(len(x[1]) for x in test_ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFxXfbeSrB4h",
    "outputId": "1fb399f5-266b-434b-c207-1725d5c56502",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.908158Z",
     "start_time": "2025-05-30T18:15:08.378001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n",
      "44\n",
      "34\n"
     ]
    }
   ],
   "execution_count": 72
  },
  {
   "cell_type": "code",
   "source": [
    "next(iter(train_ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wsIgzRtAMNQ-",
    "outputId": "6452a00e-aaa1-4fc4-f5b3-d545c309fadb",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.911470Z",
     "start_time": "2025-05-30T18:15:10.908940Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Why', 'did', \"n't\", 'you', 'use', 'a', 'pay', 'phone', '?'],\n",
       " ['¿', 'Por', 'qué', 'no', 'usaste', 'un', 'teléfono', 'de', 'pago', '?'])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 73
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create Vocabulary"
   ],
   "metadata": {
    "id": "Yqo3q9RkMkJC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "vocab = {}"
   ],
   "metadata": {
    "id": "rvyraKQ4r9gG",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.915131Z",
     "start_time": "2025-05-30T18:15:10.911883Z"
    }
   },
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "source": [
    "src_vocab_size = 10_000\n",
    "tgt_vocab_size = 10_000\n",
    "max_seq_len = 100\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "BOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "special_symbols = ['<PAD>', '<UNK>', '<BOS>', '<EOS>']"
   ],
   "metadata": {
    "id": "f4FMeg4yMP8x",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.919043Z",
     "start_time": "2025-05-30T18:15:10.915527Z"
    }
   },
   "outputs": [],
   "execution_count": 75
  },
  {
   "cell_type": "code",
   "source": [
    "def yield_tokens(dataset, lang_idx=0):\n",
    "    n = len(dataset)\n",
    "    i = 0\n",
    "\n",
    "    while i < n:\n",
    "        yield dataset[i][lang_idx]\n",
    "        i += 1"
   ],
   "metadata": {
    "id": "ujR7SLRvM1h7",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.923874Z",
     "start_time": "2025-05-30T18:15:10.919507Z"
    }
   },
   "outputs": [],
   "execution_count": 76
  },
  {
   "cell_type": "code",
   "source": [
    "src_iterator = yield_tokens(train_ds, lang_idx=0)\n",
    "tgt_iterator = yield_tokens(train_ds, lang_idx=1)"
   ],
   "metadata": {
    "id": "knnnCTpMNGMA",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:10.927743Z",
     "start_time": "2025-05-30T18:15:10.924314Z"
    }
   },
   "outputs": [],
   "execution_count": 77
  },
  {
   "cell_type": "code",
   "source": [
    "vocab[SRC_LANGUAGE] = build_vocab_from_iterator(\n",
    "    src_iterator,\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True,\n",
    "    max_tokens=src_vocab_size,\n",
    ")"
   ],
   "metadata": {
    "id": "igmo37DaNTox",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:13.106265Z",
     "start_time": "2025-05-30T18:15:10.928262Z"
    }
   },
   "outputs": [],
   "execution_count": 78
  },
  {
   "cell_type": "code",
   "source": [
    "vocab[TGT_LANGUAGE] = build_vocab_from_iterator(\n",
    "    tgt_iterator,\n",
    "    min_freq=1,\n",
    "    specials=special_symbols,\n",
    "    special_first=True,\n",
    "    max_tokens=tgt_vocab_size,\n",
    ")"
   ],
   "metadata": {
    "id": "YZ0aiHA-OAEf",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.383323Z",
     "start_time": "2025-05-30T18:15:13.107012Z"
    }
   },
   "outputs": [],
   "execution_count": 79
  },
  {
   "cell_type": "code",
   "source": [
    "vocab[SRC_LANGUAGE].set_default_index(UNK_IDX)\n",
    "vocab[TGT_LANGUAGE].set_default_index(UNK_IDX)"
   ],
   "metadata": {
    "id": "J5I7rHfFOMTP",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.385776Z",
     "start_time": "2025-05-30T18:15:15.383939Z"
    }
   },
   "outputs": [],
   "execution_count": 80
  },
  {
   "cell_type": "code",
   "source": [
    "vocab[SRC_LANGUAGE]['hello']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "g6dKNNCzOfoy",
    "outputId": "ea75d92f-e2c4-477c-ed1b-47e7c2bcef1f",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.390875Z",
     "start_time": "2025-05-30T18:15:15.386261Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2325"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 81
  },
  {
   "cell_type": "code",
   "source": [
    "vocab[TGT_LANGUAGE]['Hola']"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZJCNg2MfORYQ",
    "outputId": "a3506664-f70b-4a62-da85-b4c2e06b240f",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.395295Z",
     "start_time": "2025-05-30T18:15:15.391336Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2337"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 82
  },
  {
   "cell_type": "code",
   "source": [
    "def collate_fn(batch, vocab):\n",
    "    batch_size = len(batch)\n",
    "    srcs, tgts = zip(*batch)\n",
    "    src_vectors = torch.zeros((batch_size, max_seq_len), dtype=torch.long, device=device)\n",
    "    tgt_vectors = torch.zeros((batch_size, max_seq_len), dtype=torch.long, device=device)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        src_vectors[i] = torch.tensor(([BOS_IDX] + vocab[SRC_LANGUAGE](srcs[i]) + [EOS_IDX] + [0] * (max_seq_len - len(srcs[i])))[:max_seq_len], dtype=torch.long, device=device)\n",
    "        tgt_vectors[i] = torch.tensor(([BOS_IDX] + vocab[TGT_LANGUAGE](tgts[i]) + [EOS_IDX] + [0] * (max_seq_len - len(tgts[i])))[:max_seq_len], dtype=torch.long, device=device)\n",
    "\n",
    "    return src_vectors, tgt_vectors"
   ],
   "metadata": {
    "id": "hfK2UQZFmxQD",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.399526Z",
     "start_time": "2025-05-30T18:15:15.395754Z"
    }
   },
   "outputs": [],
   "execution_count": 83
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=64, shuffle=True, collate_fn=partial(collate_fn, vocab=vocab))\n",
    "val_dataloader = DataLoader(val_ds, batch_size=64, shuffle=True, collate_fn=partial(collate_fn, vocab=vocab))\n",
    "test_dataloader = DataLoader(test_ds, batch_size=64, shuffle=True, collate_fn=partial(collate_fn, vocab=vocab))"
   ],
   "metadata": {
    "id": "Uqxlzw-Hu_YJ",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:15:15.404987Z",
     "start_time": "2025-05-30T18:15:15.400009Z"
    }
   },
   "outputs": [],
   "execution_count": 84
  },
  {
   "cell_type": "code",
   "source": [
    "src_vocab_size = 10_000\n",
    "tgt_vocab_size = 10_000\n",
    "d_model = 512\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "num_epochs = 3\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch: {epoch+1}\\n------------------------------\")\n",
    "    transformer.train()\n",
    "    train_loss = 0\n",
    "    for data in tqdm(train_dataloader, total=len(train_dataloader)):\n",
    "        src_data, tgt_data = data\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    transformer.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in val_dataloader:\n",
    "            src_data, tgt_data = data\n",
    "            output = transformer(src_data, tgt_data[:, :-1])\n",
    "            loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_dataloader)\n",
    "    val_loss /= len(val_dataloader)\n",
    "            \n",
    "    print(f\"Epoch: {epoch+1} | Training Loss: {train_loss} | Validation Loss: {val_loss}\")\n",
    "    # torch.save(transformer.state_dict(), f'./transformer_state_dict_epoch_{epoch+1}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxUsDY5JzNj7",
    "outputId": "8193140e-cbc0-4d38-ea8d-e3f9986e5726",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:32:55.547910Z",
     "start_time": "2025-05-30T18:15:15.405875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [06:18<00:00,  4.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | Training Loss: 3.1201352871743975 | Validation Loss: 2.07179338384319\n",
      "Epoch: 2\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [05:19<00:00,  5.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 | Training Loss: 1.9061797309730013 | Validation Loss: 1.6167761028349936\n",
      "Epoch: 3\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1770/1770 [05:21<00:00,  5.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 | Training Loss: 1.5077081775261183 | Validation Loss: 1.4094878392176584\n"
     ]
    }
   ],
   "execution_count": 85
  },
  {
   "cell_type": "code",
   "source": [
    "transformer.eval()\n",
    "with torch.no_grad():\n",
    "    test_loss = 0\n",
    "    for data in tqdm(test_dataloader, total=len(test_dataloader)):\n",
    "        src_data, tgt_data = data\n",
    "        output = transformer(src_data, tgt_data[:, :-1])\n",
    "        loss = criterion(output.contiguous().view(-1, tgt_vocab_size), tgt_data[:, 1:].contiguous().view(-1))\n",
    "        test_loss += loss.item()\n",
    "    test_loss /= len(test_dataloader)\n",
    "    print(f\"Test Loss: {test_loss}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qLQfPbuV_MW4",
    "outputId": "afb704c1-4e7e-4786-bfb0-165f70ddd8f6",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:33:09.787332Z",
     "start_time": "2025-05-30T18:32:55.548462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 222/222 [00:14<00:00, 15.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.4262425480662166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 86
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T18:49:39.607670Z",
     "start_time": "2025-05-30T18:49:39.604972Z"
    }
   },
   "cell_type": "code",
   "source": "len(train_dataloader) * 64, len(val_dataloader) * 64",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113280, 14208)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 98
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inference"
   ],
   "metadata": {
    "id": "ofl363KBgiyq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# model_path = \"./transformer_epoch_3\"\n",
    "# state_dict = torch.load(model_path)\n",
    "\n",
    "src_vocab_size = 10_000\n",
    "tgt_vocab_size = 10_000\n",
    "d_model = 512\n",
    "num_heads = 4\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "num_epochs = 3\n",
    "\n",
    "# transformer_loaded = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout).to(device)\n",
    "# transformer_loaded.load_state_dict(state_dict)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsbGPbE_hFPD",
    "outputId": "7bfbe4d9-52f2-43f0-918b-7c5346aae9cf",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:34:35.810784Z",
     "start_time": "2025-05-30T18:34:35.807856Z"
    }
   },
   "outputs": [],
   "execution_count": 88
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-30T18:34:36.294075Z",
     "start_time": "2025-05-30T18:34:36.290972Z"
    }
   },
   "cell_type": "code",
   "source": "tokenizer[SRC_LANGUAGE]('Hello, i am a teacher')",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello', ',', 'i', 'am', 'a', 'teacher']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 89
  },
  {
   "cell_type": "code",
   "source": [
    "def translate(src):\n",
    "    src_tokens = tokenizer[SRC_LANGUAGE](src)\n",
    "    tgt_tokens = [\"<BOS>\"]\n",
    "\n",
    "    src_vectors = torch.tensor(([BOS_IDX] + vocab[SRC_LANGUAGE](src_tokens) + [EOS_IDX] + [0] * (max_seq_len - len(src_tokens)))[:max_seq_len], dtype=torch.long, device=device).unsqueeze(0)\n",
    "\n",
    "    for i in range(max_seq_len):\n",
    "        tgt_vectors = torch.tensor((vocab[TGT_LANGUAGE](tgt_tokens) + [0] * (max_seq_len - len(tgt_tokens)))[:max_seq_len], dtype=torch.long, device=device).unsqueeze(0)\n",
    "        output = transformer(src_vectors, tgt_vectors)\n",
    "        idx = torch.argmax(nn.functional.softmax(output, dim=2)[0][i]).item()\n",
    "        tgt_tokens.append(vocab[TGT_LANGUAGE].lookup_token(idx))\n",
    "\n",
    "        if idx == EOS_IDX:\n",
    "            break\n",
    "\n",
    "    return \" \".join(tgt_tokens).replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\").replace(\"<PAD>\", \"\").strip()"
   ],
   "metadata": {
    "id": "x0NYt9BPMufm",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:48:32.144303Z",
     "start_time": "2025-05-30T18:48:32.141163Z"
    }
   },
   "outputs": [],
   "execution_count": 94
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"Hello, I am a teacher.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "d9xThngkeK6W",
    "outputId": "c39a69d3-9ebe-4353-a7e9-0cf6b17195a3",
    "ExecuteTime": {
     "end_time": "2025-05-30T18:48:33.053061Z",
     "start_time": "2025-05-30T18:48:32.994906Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hola , soy profesor .'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"My name is John.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "lE7m-fQefb0V",
    "outputId": "c952c1ec-ce63-49f8-d03f-9228596adfd0",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:08:43.973294Z",
     "start_time": "2025-05-30T17:08:43.927579Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mi nombre es John .'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"I am learning Spanish.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QyHIl2fhfp2O",
    "outputId": "247f0f94-5807-458f-92d3-979f922935f3",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:08:46.430153Z",
     "start_time": "2025-05-30T17:08:46.404182Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Estoy aprendiendo español .'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"I eat apples.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "KahapCeCfwMr",
    "outputId": "69c4a3e7-c97d-4a88-9ad0-fad3ea4da9e7",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:08:48.624365Z",
     "start_time": "2025-05-30T17:08:48.599692Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yo como manzanas .'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"I have three books and two pens.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "q_7aRX5Hf0A7",
    "outputId": "60b2db64-f72b-49b3-de2b-870496c632d6",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:08:53.642541Z",
     "start_time": "2025-05-30T17:08:53.600916Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tengo tres libros y dos <UNK> .'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"Do you work in an office?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OQkoUnAmgMw1",
    "outputId": "8a91b56d-f187-4f57-bd5c-eb7a59d01724",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:08:56.900383Z",
     "start_time": "2025-05-30T17:08:56.853094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿ Tú trabajo en una oficina ?'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 52
  },
  {
   "cell_type": "code",
   "source": [
    "translate(\"How are you?\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "eQ3u-gnngu_l",
    "outputId": "108177f8-be87-4c0f-d2a3-5fa0c2353874",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:09:03.317559Z",
     "start_time": "2025-05-30T17:09:03.290633Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¿ Cómo estás ?'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "source": [
    "eng, spa = test_lines[0].split('\\t')\n",
    "print(eng)\n",
    "print(spa)\n",
    "translate(eng)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "_p_dI_QOiWRJ",
    "outputId": "9820902f-7f01-48a6-aeb4-a9caebddb2c4",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:09:08.412303Z",
     "start_time": "2025-05-30T17:09:08.369680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom's flight was delayed.\n",
      "El vuelo de Tom fue retrasado.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'El vuelo de Tom estaba <UNK> .'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "source": [
    "eng, spa = test_lines[500].split('\\t')\n",
    "print(eng)\n",
    "print(spa)\n",
    "translate(eng)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "T0VbizfWil7D",
    "outputId": "239fdf9c-a5eb-4466-d355-53d31285a9e4",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:09:14.882224Z",
     "start_time": "2025-05-30T17:09:14.819457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't believe Tom really said no to me.\n",
      "No puedo creer que Tom verdaderamente me haya dicho no.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'No puedo creer que Tom realmente dijo que no me dijo .'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "source": [
    "eng, spa = train_lines[1000].split('\\t')\n",
    "print(eng)\n",
    "print(spa)\n",
    "translate(eng)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "vp-71fggiuM5",
    "outputId": "354adf16-99c6-42b6-8ec8-a43f10536df5",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:09:40.835022Z",
     "start_time": "2025-05-30T17:09:40.771297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tom eats breakfast every morning at six o'clock.\n",
      "Tom desayuna a las seis todas las mañanas.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tom come todos los días a las seis .'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "source": [
    "eng, spa = train_lines[10000].split('\\t')\n",
    "print(eng)\n",
    "print(spa)\n",
    "translate(eng)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "id": "fGxzFl4Ui0lY",
    "outputId": "49683592-a50d-4930-b16a-c487372ab486",
    "ExecuteTime": {
     "end_time": "2025-05-30T17:09:41.512147Z",
     "start_time": "2025-05-30T17:09:41.473871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He can speak five languages.\n",
      "Él habla cinco lenguas.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Él sabe hablar cinco idiomas .'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 57
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Export model and vocabulary"
   ],
   "metadata": {
    "id": "3HIFB166pJMq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(vocab[SRC_LANGUAGE], \"./vocab-english\")\n",
    "torch.save(vocab[TGT_LANGUAGE], \"./vocab-spanish\")"
   ],
   "metadata": {
    "id": "NRQyHCffi7-s"
   },
   "execution_count": 197,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(tokenizer[SRC_LANGUAGE], \"./tokenizer-english\")\n",
    "torch.save(tokenizer[TGT_LANGUAGE], \"./tokenizer-spanish\")"
   ],
   "metadata": {
    "id": "DFaLmjFWqB3e"
   },
   "execution_count": 203,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(transformer, \"./transformer_model\")"
   ],
   "metadata": {
    "id": "v5leNOqGqmT3"
   },
   "execution_count": 210,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "9ndAILIdq58F"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
